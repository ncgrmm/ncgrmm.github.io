{
  "hash": "7300de355570045bcd9acffb44e9c664",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"Bayesian Inference and Factor Graphs\"\nauthor: \"Nico Grimm\"\ndate: \"2025-07-29\"\ntoc: true\nhtml-math-method: katex\ncategories: [probabilistic-ml, probability-theory]\nengine: julia\n---\n## Introduction\n\n## Bayesian Inference Model\nDerived from a fundamental result in probability theory, the *Bayesian Inference Model* is one of the basic concepts in probabilistic machine learning. It represents the elemental idea of updating prior beliefs over model parameters through data.\n$$ p(B \\: \\vert \\: A) = \\frac{p(A \\: \\vert \\: B)\\cdot p(B)}{p(A)} $$ {#eq-bayes}\nIn machine learning, we typically have a model which can be specified by some set of parameters $\\mathbf{\\Phi}$ deal with training data $\\mathcal{D}$. Usually, the parameters are directly updated by optimizing a given metric on the training data, e.g. minimizing a loss function. However, in this setting we are specifiying a so-called *prior distribution* over $\\mathbf{\\Phi}$ and update the distribution through training. Not only does this allow to incorporate assumptions over possibly important model parameters, but also captures the model's uncertainty of the weight's values after training and makes it possible to compute the uncertainty of predictions.\n\nStarting off with *Bayes' Rule* (see @eq-bayes), which relates the probability of $B$ to the probability of $B$ given $A$. By replacing $B$ with $\\mathbf{\\Phi}$ and $A$ with $\\mathcal{D}$ we end up with the basic formula of *Bayesian Inference*:\n$$p(\\mathbf{\\Phi} \\: \\vert \\: \\mathcal{D}) \\propto p(\\mathcal{D} \\: \\vert \\: \\mathbf{\\Phi}) \\cdot p(\\mathbf{\\Phi})$$\nThis is exactly the tool to achieve what was proposed earlier. From the prior belief over parameters $p(\\mathbf{\\Phi})$ we can obtain an updated distribution after seeing the data $p(\\mathbf{\\Phi} \\: \\vert \\: \\mathcal{D})$, called *posterior distribution*, by multiplying with $p(\\mathcal{D} \\: \\vert \\: \\mathbf{\\Phi})$. This term is called *likelihood* and is very important. It is the probability of the training data having been generated by the current parameter values. It basically represents the actual model in the equation, as it describes the probability of the model output being the target value given the current parameter values. \n\nNow what about $p(\\mathcal{D})$? This term is called *model evidence* and essentially captures to which extent the proposed model, including it's prior assumptions, is capable of fitting the data, because in order to calculate it, we need to integrate the product of prior and likelihood over all possible parameter values. In practice, it is often ommited, because it is\n\n* typically very hard to compute exactly\n* constant for a given model\n* unnecessary for parameter estimation of the posterior\n\n## Factor Graphs\n\n## Sum-Product-Algorithm\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}